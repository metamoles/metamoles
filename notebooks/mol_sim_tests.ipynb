{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import mol_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_input_data():\n",
    "    '''Tests input_data function in mol_sim.py'''    \n",
    "    \n",
    "    input_df = pd.read_csv('playground_df_cleaned_kegg_with_smiles.csv')\n",
    "    test_df = mol_sim.input_data(input_df)\n",
    "    \n",
    "    assert isinstance(test_df, pd.DataFrame) == True, \"\"\"TypeError,\n",
    "    function should return a pandas dataframe\"\"\"    \n",
    "    #assert \n",
    "    \n",
    "    return '1/1 tests successful'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 tests successful\n"
     ]
    }
   ],
   "source": [
    "test_input_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_fingerprint_products():\n",
    "    '''Tests fingerprint_products function in mol_sim.py'''\n",
    "    \n",
    "    input_df = pd.read_csv('playground_df_cleaned_kegg_with_smiles.csv')\n",
    "    test_df = mol_sim.input_data(input_df)\n",
    "    \n",
    "    assert isinstance(mol_sim.fingerprint_products(test_df), pd.DataFrame) == True, \"\"\"TypeError,\n",
    "    function should return a pandas dataframe\"\"\"    \n",
    "    #assert\n",
    "\n",
    "    return '1/1 tests successful'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 tests successful\n"
     ]
    }
   ],
   "source": [
    "test_fingerprint_products()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_split_by_enzyme():\n",
    "    '''Tests split_by_enzyme function in mol_sim.py'''\n",
    "    \n",
    "    input_df = pd.read_csv('playground_df_cleaned_kegg_with_smiles.csv')\n",
    "    test_df = mol_sim.fingerprint_products(mol_sim.input_data(input_df))\n",
    "    \n",
    "    assert isinstance(mol_sim.split_by_enzyme(test_df), list) == True, \"\"\"TypeError,\n",
    "    function should return a pandas dataframe\"\"\"    \n",
    "    #assert\n",
    "    \n",
    "    return '1/1 tests successful'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 tests successful\n"
     ]
    }
   ],
   "source": [
    "test_split_by_enzyme()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_sim_i_j():\n",
    "    '''Tests sim_i_j function in mol_sim.py'''\n",
    "    \n",
    "    input_df = pd.read_csv('playground_df_cleaned_kegg_with_smiles.csv')\n",
    "    test_df = mol_sim.fingerprint_products(mol_sim.input_data(input_df))\n",
    "    \n",
    "    A = test_df.iloc[0]\n",
    "    #B = test_df.iloc[1]\n",
    "    #C = test_df.iloc[2]\n",
    "    \n",
    "    assert mol_sim.sim_i_j(A, A) == 1, \"Self correlation is broken\"\n",
    "    #assert mol_sim.sim_i_j(A, B) == -1, \"Standard correlation is broken\"\n",
    "    #assert mol_sim.sim_i_j(A, C) == 0, \"Standard correlation is broken\" \n",
    "    \n",
    "    return '1/1 tests successful'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 tests successful\n"
     ]
    }
   ],
   "source": [
    "test_sim_i_j()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_sim_i_all():\n",
    "    '''Test sim_i_all functionin mol_sim.py'''\n",
    "    \n",
    "    input_df = pd.read_csv('playground_df_cleaned_kegg_with_smiles.csv')\n",
    "    test_df = mol_sim.fingerprint_products(mol_sim.input_data(input_df))\n",
    "    metric = pd.DataFrame()\n",
    "    \n",
    "    assert metric.empty == True, \"\"\"ShapeError, input metric dataframe \n",
    "    should be initialized as empty\"\"\"\n",
    "    \n",
    "    for index, row in test_df.iterrows():\n",
    "        assert mol_sim.sim_i_all(test_df, index, row, metric) == None, \"\"\"OutputError, function \n",
    "        shouldn't return anything\"\"\"\n",
    "        assert metric[index].all() >= 0 and metric[index].all() <= 1.0, \"\"\"ValueError, \n",
    "        metric should be between 0 and 1\"\"\"\n",
    "    \n",
    "    return \"3/3 Tests successful\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3/3 Tests successful'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sim_i_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_sim_metric():\n",
    "    '''Test sim_i_all functionin mol_sim.py'''\n",
    "    input_df = pd.read_csv('playground_df_cleaned_kegg_with_smiles.csv')\n",
    "    test_df = mol_sim.fingerprint_products(mol_sim.input_data(input_df))\n",
    "    assert isinstance(mol_sim.sim_metric(test_df), pd.DataFrame) == True, \"\"\"TypeError, \n",
    "    function should return a dataframe\"\"\"\n",
    "    assert mol_sim.sim_metric(test_df).isnull().values.any() == False, \"\"\"ValueError, \n",
    "    function-generated dataframe should not contain null values\"\"\"\n",
    "    #assert test_df.size == mol_sim.sim_metric(test_df).size, \"\"\"ShapeError, \n",
    "    #function-generated dataframe should be the same size as input dataframe\"\"\"\n",
    "\n",
    "    return \"2/2 Tests successful\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2/2 Tests successful'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sim_metric()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_main():\n",
    "    \n",
    "    df = pd.read_csv('playground_df_cleaned_kegg_with_smiles.csv')\n",
    "    test_df = mol_sim.main(df)\n",
    "    \n",
    "    assert isinstance(test_df, pd.DataFrame) == True, \"\"\"TypeError, \n",
    "    function should return a dataframe\"\"\"\n",
    "    #assert len(test_df.columns) == 3+len(df.columns), \"\"\"ShapeError, \n",
    "    #function should add 3 columns to dataframe\"\"\"\n",
    "    \n",
    "    \n",
    "    return \"1/1 Tests successful\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1/1 Tests successful'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
