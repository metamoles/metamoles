{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import ast\n",
    "\n",
    "df_cpd = pd.read_csv('../datasets/df_cpd.csv', index_col = 0)\n",
    "df_rxn = pd.read_csv('../datasets/df_rxns.csv', index_col = 0)\n",
    "df_enz = pd.read_csv('../datasets/df_enzrxns.csv', index_col = 0)\n",
    "df_cpd = df_cpd.set_index(keys ='UNIQUE-ID')\n",
    "df_rxn = df_rxn.set_index(keys = 'UNIQUE-ID')\n",
    "df_enz = df_enz.set_index(keys = 'UNIQUE-ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recover_list(df, column):\n",
    "    \"\"\"This function will recover a list formatted string read from .csv into a list\"\"\"\n",
    "    assert type(df[column][0]) != type([]), \"TypeError: The data type is already a list, it should not be converted again\"\n",
    "    replacement = []\n",
    "    for index, row in df.iterrows():\n",
    "\n",
    "        data = []\n",
    "\n",
    "        if type(row[column]) == type('string'):\n",
    "            data = ast.literal_eval(row[column])\n",
    "        else:\n",
    "            pass\n",
    "        replacement.append(data)\n",
    "    df[column] = replacement\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change PubChemID into int type in df_cpd\n",
    "def recover_cpd_pubchemid(df = df_cpd):\n",
    "\n",
    "    PubChemID_int = df['PubChemID'].fillna(0).astype(int)\n",
    "    df['PubChemID'] = PubChemID_int\n",
    "    return df\n",
    "\n",
    "# Recover list format of df_rxn\n",
    "def recover_rxn(df = df_rxn):\n",
    "    rxn_list_fix = ['EC-NUMBER', 'ERXN-NUMBER', 'SUBSTRATES', 'PRODUCTS']\n",
    "    for col in rxn_list_fix:\n",
    "        recover_list(df, col)\n",
    "    return df\n",
    "\n",
    "# Recover list format of df_enz\n",
    "def recover_enz(df = df_enz):\n",
    "\n",
    "    enz_list_fix = ['REACTION', 'ALTERNATIVE-SUBSTRATES', '^SUBSTRATE', 'KM', 'KCAT', 'VMAX']\n",
    "    for col in enz_list_fix:\n",
    "        recover_list(df, col)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cpd = recover_cpd_pubchemid(df_cpd)\n",
    "df_rxn = recover_rxn(df_rxn)\n",
    "df_enz = recover_enz(df_enz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_inchi(ID):\n",
    "\n",
    "    \"\"\"This function accept UNIQUE-ID and return InChI string of a certain compound\"\"\"\n",
    "    if ID in df_cpd['PubChemID']:\n",
    "        inchi = df_cpd['INCHI'][ID]\n",
    "    else:\n",
    "        inchi = '0'\n",
    "\n",
    "\n",
    "    return inchi\n",
    "\n",
    "def get_smiles(ID):\n",
    "\n",
    "    \"\"\"This function accept UNIQUE-ID and return SMILES string of a certain compound\"\"\"\n",
    "\n",
    "    if ID in df_cpd['PubChemID']:\n",
    "        smiles = df_cpd['SMILES'][ID]\n",
    "    else:\n",
    "        smiles = '0'\n",
    "\n",
    "    return smiles\n",
    "\n",
    "def get_pubchem(ID):\n",
    "\n",
    "    \"\"\"This function accept UNIQUE-ID and return InChI string of a certain compound\"\"\"\n",
    "    if ID in df_cpd['PubChemID']:\n",
    "        pubchem = df_cpd['PubChemID'][ID]\n",
    "    else:\n",
    "        pubchem = '0'\n",
    "\n",
    "    return pubchem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'../datasets/df_cpd.csv' does not exist: b'../datasets/df_cpd.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-68f416349dcc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mast\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mdf_cpd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'../datasets/df_cpd.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex_col\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mdf_rxn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'../datasets/df_rxns.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex_col\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mdf_enz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'../datasets/df_enzrxns.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex_col\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    700\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    701\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 702\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    703\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    704\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    427\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    428\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 429\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    430\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    431\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 895\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    896\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1120\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'c'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1121\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'c'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1122\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1123\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1124\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'python'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1851\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'usecols'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1852\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1853\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1854\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1855\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] File b'../datasets/df_cpd.csv' does not exist: b'../datasets/df_cpd.csv'"
     ]
    }
   ],
   "source": [
    "\n",
    "# df_master here\n",
    "\n",
    "def rxn_to_EC(df = df_rxn):\n",
    "\n",
    "    EC = []\n",
    "    rxn = []\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "\n",
    "        if len(row['EC-NUMBER']) > 1:\n",
    "            for i in range(len(row['EC-NUMBER'])):\n",
    "                EC.append(row['EC-NUMBER'][i])\n",
    "                rxn.append(index)\n",
    "        elif len(row['EC-NUMBER']) == 1:\n",
    "            EC.append(row['EC-NUMBER'][0])\n",
    "            rxn.append(index)\n",
    "        else:\n",
    "            EC.append('No_Data')\n",
    "            rxn.append(index)\n",
    "\n",
    "    df_master = pd.DataFrame({'EC-NUMBER' : EC,\n",
    "                              'UNIQUE-ID' : rxn})\n",
    "\n",
    "    rxn_num = []\n",
    "    subs = []\n",
    "    pdts = []\n",
    "    gibbs = []\n",
    "\n",
    "    for index, row in df_master.iterrows():\n",
    "        ID = row['UNIQUE-ID']\n",
    "        rxn_num.append(df['ERXN-NUMBER'][ID])\n",
    "        subs.append(df['SUBSTRATES'][ID])\n",
    "        pdts.append(df['PRODUCTS'][ID])\n",
    "        gibbs.append(df['GIBBS'][ID])\n",
    "\n",
    "    df_master['ERXN-NUMBER'] = rxn_num\n",
    "    df_master['SUBSTRATES'] = subs\n",
    "    df_master['PRODUCTS'] = pdts\n",
    "    df_master['GIBBS'] = gibbs\n",
    "\n",
    "    return df_master\n",
    "# df_sorted here\n",
    "\n",
    "def sort_df(df):\n",
    "    df_sorted = df.sort_values(by=['EC-NUMBER'])\n",
    "    df_sorted.reset_index(inplace=True, drop=True)\n",
    "    for index, row in df_sorted.iterrows():\n",
    "\n",
    "        if math.isnan(row['GIBBS']):\n",
    "            df_sorted['GIBBS'][index] = 'No-Data'\n",
    "\n",
    "    return df_sorted\n",
    "\n",
    "def combine_EC(df):\n",
    "\n",
    "    EC_a = 'EC-1'\n",
    "\n",
    "    EC = []\n",
    "    ID = []\n",
    "    erxn = []\n",
    "    subs = []\n",
    "    pdts = []\n",
    "    gibbs = []\n",
    "    counter = 0\n",
    "\n",
    "    ID_temp = []\n",
    "    erxn_temp = []\n",
    "    subs_temp = []\n",
    "    pdts_temp = []\n",
    "    gibbs_temp = []\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "\n",
    "        if row['EC-NUMBER'] == EC_a:\n",
    "            ID_temp.append(row['UNIQUE-ID'])\n",
    "            erxn_temp.append(row['ERXN-NUMBER'])\n",
    "            subs_temp.append(row['SUBSTRATES'])\n",
    "            pdts_temp.append(row['PRODUCTS'])\n",
    "            gibbs_temp.append(row['GIBBS'])\n",
    "            counter += 1\n",
    "\n",
    "        elif counter == 0:\n",
    "            ID.append(row['UNIQUE-ID'])\n",
    "            erxn.append(row['ERXN-NUMBER'])\n",
    "            subs.append(row['SUBSTRATES'])\n",
    "            pdts.append(row['PRODUCTS'])\n",
    "            gibbs.append(row['GIBBS'])\n",
    "\n",
    "            EC.append(EC_a)\n",
    "            EC_a = row['EC-NUMBER']\n",
    "        else:\n",
    "            ID.append(ID_temp)\n",
    "            erxn.append(erxn_temp)\n",
    "            subs.append(subs_temp)\n",
    "            pdts.append(pdts_temp)\n",
    "            gibbs.append(gibbs_temp)\n",
    "\n",
    "            ID_temp = []\n",
    "            erxn_temp = []\n",
    "            subs_temp = []\n",
    "            pdts_temp = []\n",
    "            gibbs_temp = []\n",
    "\n",
    "            EC.append(EC_a)\n",
    "            counter = 0\n",
    "            EC_a = row['EC-NUMBER']\n",
    "\n",
    "    df_sorted_master = pd.DataFrame({'EC-NUMBER' : EC,\n",
    "                                    'UNIQUE-ID' : ID,\n",
    "                                    'ERXN-NUMBER' : erxn,\n",
    "                                    'SUBSTRATES' : subs,\n",
    "                                    'PRODUCTS' : pdts,\n",
    "                                    'GIBBS' : gibbs})\n",
    "\n",
    "    df_sorted_master.set_index(keys=['EC-NUMBER'], inplace=True)\n",
    "\n",
    "    return df_sorted_master\n",
    "# drop redundancy\n",
    "\n",
    "def drop_EC_redundancy(df):\n",
    "\n",
    "    drop = []\n",
    "    for index, row in df.iterrows():\n",
    "        if index.count('.') < 'EC-1.1.1.1'.count('.'):\n",
    "            #print(index)\n",
    "            drop.append(index)\n",
    "\n",
    "    df_sorted_master_drop = df\n",
    "    for item in drop:\n",
    "        df_sorted_master_drop = df_sorted_master_drop.drop(item)\n",
    "\n",
    "    return df_sorted_master_drop\n",
    "# first version df_master_1st\n",
    "\n",
    "def master_direction(df):\n",
    "\n",
    "#    df_master_1st = pd.read_csv('df_master_1st.csv')\n",
    "    df_master = df.drop(['UNIQUE-ID', 'ERXN-NUMBER'], axis = 1)\n",
    "    df_master['DIRECTION'] = 1\n",
    "\n",
    "    temp = []\n",
    "    for index, row in df_master.iterrows():\n",
    "        if type(row['GIBBS']) == str and row['GIBBS'][0] == '[':\n",
    "            temp.append(row['GIBBS'][1:-1].split(\",\"))\n",
    "        elif type(row['GIBBS']) == list:\n",
    "            temp.append(row['GIBBS'])\n",
    "        elif row['GIBBS'] == 'No-Data':\n",
    "            temp.append(row['GIBBS'])\n",
    "        else:\n",
    "            temp.append(float(row['GIBBS']))\n",
    "    df_master['GIBBS'] = temp\n",
    "\n",
    "    recover_list(df_master, 'SUBSTRATES')\n",
    "    recover_list(df_master, 'PRODUCTS')\n",
    "\n",
    "    return df_master\n",
    "\n",
    "# single liner\n",
    "\n",
    "def flatten_df(df):\n",
    "\n",
    "    EC = []\n",
    "    substrate = []\n",
    "    products = []\n",
    "    gibbs = []\n",
    "    for index, row in df.iterrows():\n",
    "        if type(row['SUBSTRATES'][0]) == list:\n",
    "            for item in row['SUBSTRATES']:\n",
    "                EC.append(row['EC-NUMBER'])\n",
    "                substrate.append(item)\n",
    "            for item in row['PRODUCTS']:\n",
    "                products.append(item)\n",
    "            for item in row['GIBBS']:\n",
    "                gibbs.append(item)\n",
    "        else:\n",
    "            EC.append(row['EC-NUMBER'])\n",
    "            substrate.append(row['SUBSTRATES'])\n",
    "            products.append(row['PRODUCTS'])\n",
    "            gibbs.append(row['GIBBS'])\n",
    "    #print ('EC-NUMBER count', len(EC), '\\n SUBSTRATES count', len(substrate), '\\n PRODUCTS count', len(products), '\\n GIBBS count', len(gibbs))\n",
    "\n",
    "    df_master_flattened = pd.DataFrame({'EC-NUMBER': EC,\n",
    "                                       'SUBSTRATES': substrate,\n",
    "                                       'PRODUCTS': products,\n",
    "                                       'GIBBS': gibbs})\n",
    "    #df_master_flattened.to_csv('df_master_flattened.csv')\n",
    "\n",
    "    return df_master_flattened\n",
    "\n",
    "def single_liner(df):\n",
    "\n",
    "    EC = []\n",
    "    subs = []\n",
    "    for index, row in df.iterrows():\n",
    "        if type(row['SUBSTRATES']) == list:\n",
    "            for item in row['SUBSTRATES']:\n",
    "                EC.append(row['EC-NUMBER'])\n",
    "                subs.append(item)\n",
    "        else:\n",
    "            EC.append(row['EC-NUMBER'])\n",
    "            subs.append(row['SUBSTRATES'])\n",
    "\n",
    "    df_subs = pd.DataFrame({'EC-NUMBER': EC,\n",
    "                           'SUBSTRATES': subs})\n",
    "\n",
    "    EC = []\n",
    "    pdts = []\n",
    "    for index, row in df_master_flattened.iterrows():\n",
    "        if type(row['PRODUCTS']) == list:\n",
    "            for item in row['PRODUCTS']:\n",
    "                EC.append(row['EC-NUMBER'])\n",
    "                pdts.append(item)\n",
    "        else:\n",
    "            EC.append(row['EC-NUMBER'])\n",
    "            pdts.append(row['PRODUCTS'])\n",
    "\n",
    "    df_pdts = pd.DataFrame({'EC-NUMBER': EC,\n",
    "                           'PRODUCTS': pdts})\n",
    "\n",
    "    return [df_subs, df_pdts]\n",
    "\n",
    "# dropping\n",
    "# dropping the weird EC-NUMBER\n",
    "\n",
    "def drop_single(df):\n",
    "\n",
    "    drop = []\n",
    "    for index, row in df.iterrows():\n",
    "        if row['EC-NUMBER'].count('.') < 'EC-1.1.1.1'.count('.'):\n",
    "            #print(index)\n",
    "            #drop.append(row['EC-NUMBER'])\n",
    "            drop.append(index)\n",
    "        elif row['EC-NUMBER'][0] == '|' and row['EC-NUMBER'][-1] == '|':\n",
    "            #drop.append(row['EC-NUMBER'])\n",
    "            drop.append(index)\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    df_subs_dropped = df\n",
    "    for item in drop:\n",
    "        df_subs_dropped = df.drop(item)\n",
    "\n",
    "    return df_subs_dropped\n",
    "\n",
    "def subs_EC(df, ec:str):\n",
    "\n",
    "    EC = []\n",
    "    subs = []\n",
    "    for index, row in df.iterrows():\n",
    "        if row['EC-NUMBER'][:4] == ec:\n",
    "            EC.append(row['EC-NUMBER'])\n",
    "            subs.append(row['SUBSTRATES'])\n",
    "    df_subs_ec = pd.DataFrame({'EC-NUMBER': EC,\n",
    "                               'SUBSTRATES': subs})\n",
    "    return df_subs_ec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
